
# k-近邻算法的原理

### 给定分类已定的一个训练数据集，当要对新的实例进行分类时，对当前实例和训练数据集中的数据进行距离度量（用特征空间中两个实例点的距离近似反映两个实例的相似程度），按照距离大小升序排列，取前 k 个数据的分类，然后通过特定的分类决策规则作用于前 k 个数据的分类为其划分类别。k-近邻法的三个基本要素：k 值的确定、距离的度量、分类决策规则。


# k-近邻算法
### 输入：训练数据集 $$T=\{(x_{1},y_{1}),(x_{2},y_{2}),(x_{3},y_{3}),...,(x_{n},y_{n})\}$$ 其中,$x_{i}\in X \subseteq  R^n $ 为实例的特征向量，$y_{i} \in Y =\{c_{1},c_{2},...,c_{k}\} $ 为实例的类别，i=1,2,...,n

### 输出:  实例 x 所属的类别 y .
### 1.根据给定的距离度量，按照距离大小升序排列，前 k 个数据点的领域记作$N_{k}(x)$ ;
### 2.在$N_{k}(x)$ 中根据分类决策规则(如多数表决)决定 x 的类别 y:$$y=\mathop{\arg\max}_{c_{j}}\sum_{x_{i}\in N_{k}(x)}I(y_{i}=c_{j}),i=1,2,3,...,n;j=1,2,3...,k $$ I 为指示函数，即当$c_{i}=y_{i}$ 时$I = 1$，否则$ I = 0$.


